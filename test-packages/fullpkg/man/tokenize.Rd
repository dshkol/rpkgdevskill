% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenize}
\title{Tokenize Text into Words}
\usage{
tokenize(text, lowercase = TRUE)
}
\arguments{
\item{text}{Character vector of text to tokenize.}

\item{lowercase}{Logical. Convert to lowercase? Default is \code{TRUE}.}
}
\value{
A list of character vectors, one per input text element.
}
\description{
Splits text into individual words, removing punctuation and
optionally converting to lowercase.
}
\examples{
tokenize("Hello, World!")
tokenize(c("First sentence.", "Second one."))
}
\seealso{
\code{\link[=count_words]{count_words()}} for counting word frequencies,
\code{\link[=word_stats]{word_stats()}} for summary statistics.
}
